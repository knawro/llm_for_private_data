# Plan of the tutorial

</br>

* LLM Overview

* Transformers
  
  * Attention

* LLM Customization

* LLM Fine-tunning

* Retrieval Augmented Generation (RAG)

</br>
</br>

<small>We gratefully acknowledge Poland's high-performance Infrastructure PLGrid ACK Cyfronet AGH for providing computer facilities and support within computational grant *plgeurocctt*</small>